## and or

and：当第一句返回True，执行第二句，类似JS的&&，前后不能跟变量名
or：第一句的返回值不管是对错，都执行第二句，类似JS的||，前后不能跟变量名

```python
hasattr(Class, "k") and setattr(class, "k", "v") # 语法正确
a = hasattr(Class, "k") and setattr(class, "k", "v") # 语法正确
a and setattr(class, "k", "v") # 语法错误
hasattr(Class, "k") and a # 语法错误
hasattr(Class, "k") and a = setattr(class, "k", "v") # 语法错误
```

##多进程

```python
# 对数组做分片，分成n个小数组分配到每个进程。适合千以下小数组
def circulation_process_worker(count, target):
    # 循环多进程
    workers = os.cpu_count()
    print(workers)
    
    def cb(r):
        print(r.result())
        
    """
    ThreadPoolExecutor 为threading的封装。因为有GIL锁的存在, 每个时刻只有一个线程处于运行状态，所以Python无法实现多线程任务并行，适合IO密集
    ProcessPoolExecutor 为 multiprocessing 的封装，可以使用多核，适合CPU密集
    """
    with concurrent.futures.ProcessPoolExecutor() as executor:
        print('处理器数量:' + str(workers))
        for i in range(workers):
            start_idx = int(count / workers * i)
            end_idx = int(count / workers * (i + 1))
            if i == workers - 1:
                end_idx = end_idx - 1
            # 提交一个任务
            future = executor.submit(target, start_idx, end_idx)
            # 增加异步回调
            future.add_done_callback(cb)
    print('完成')
    
circulation_process_worker(数组长度, 方法)

# 适合数量上千的数组
# 不对数组做分片，防止一次塞入大数组导致内存过大
# 循环数组，每次取n个，加入到进程队列
def circulation_process_worker(arr, target):
    
    with concurrent.futures.ProcessPoolExecutor() as executor:
        step = 100 # step在可能范围内越大越好，如果小了需要等待等待较长时间
        # 遍历数组，每次取step个元素
        for sub_arr in [arr[i:i + step] for i in range(0, len(arr), step)]:
            # 对应的参数数组和在后面累加
            for result in executor.map(target, sub_arr, list(map(lambda x: x + 1, sub_arr))):
                # 阻塞直到map中的任务完成
                print(result)
                
circulation_process_worker([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], 方法)
```

## 内存手动释放

```
import gc
del obj
# 立刻回收
gc.collect()
```

