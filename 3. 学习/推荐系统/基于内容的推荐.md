基于内容的推荐只有一个关键点——标签，将产品分解为标签，根据用户行为（购买、浏览）将用户也描述为标签：例如用户购买了产品，将该产品的所有标签赋值给用户，每个标签+1分，浏览则+0.5分，离线计算；针对新产品，分别计算每个用户的标签与每个新产品的相似度，可使用在线实时计算

优势：

1. 推荐结果可理解：标签
2. 推荐结果稳定性强：对于用户行为不丰富的类型，协同过滤很难找到同兴趣用户或关联产品，稀疏度太高。标签对用户兴趣捕捉稳定性远远高于单个产品
3. 便于人机协作：用户可勾选或关注推荐标签

劣势：

1. 不适合发现惊喜：如果一个产品不易于被标签穷举或标签还没出现，则很难被准确推荐
2. 在线应用复杂度高：需要基于每个用户来计算相似产品

两种方法：

方法一（one-hot编码 独热编码）：

1. 取出每个物品权重排名靠前的n个词作为标签，构建稀疏向量

2. 获取每个用户最近操作过的物品的标签，构建稀疏向量

3. 计算用户和物品、物品之间的相似度

4. 用户兴趣标签、人口统计学信息处理

   // 将每个标签（和性别年龄）分别作为向量的前几个维度，记录每个物品是否有这些属性；用户在选择标签时，将用户标签向量重新赋值，例如 0 1 0 0 xxx 改为 0 0 1 0 xxx

   用户的兴趣标签可扩展：通过话题聚类或找相似词，将相似的标签给用户（正确的做法是标签归一化，只保留同义标签中最正确的一个）

   标签过滤：

   1. 去掉词频很高的停止词
   2. 去掉同义词

   **可以给新用户打上整个系统最热门的标签（当用户未选择标签时，打上所有标签，数据库中不记录，只在推荐系统做判断）**

方法二（Embedding）：

1. 将所有物品的文字提取出来构建模型

2. 获取每个物品的embedding

   word2vec：分词，将每个词的词向量累加（求平均？），作为句子/文档的向量，在相关语义计算方面有优势，对于15字以内短句有效；简单的向量相加，丢掉了很多词和词之间的意思，无法更精确表达句子和句子之间的关系

   tf-idf：分词，以每个词的tf-idf为权重，对所有词向量加权平均

   doc2vec：适合长句子（效果较差）

3. 将用户最近操作过的物品的embedding取平均值，作为用户embedding

4. 相似度计算

5. 用户自己选择的兴趣标签和人口统计学信息如何处理

6. 聚类如何使用

7. 