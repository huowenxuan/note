## 算法

### 协同过滤

推荐系统主要分两步，召回和排序，召回就是用各种推荐算法找到给用户推荐的内容，排序阶段对这些内容进行排序，预测哪些是用户更喜欢的，排在前面

经过学习和了解，在召回阶段基本上所有的推荐算法都是围绕两类，协同过滤算法和基于内容的推荐算法

重点就是所有用户之间的协同，是大家的合作，根据大家的行为，找到你感兴趣的内容，这里是通过行为来推荐，不关注内容

基于用户的协同过滤就是：和你相似的用户也喜欢的物品，就是和你相似的用户也喜欢的物品，就认为你也喜欢，喜欢的人越多，你的喜欢程度越高，如果其他人收藏或转发，那么喜欢程度更高

基于物品的协同过滤就是：找你喜欢的物品相似的物品

原理是用户和物品构建为一个矩阵，这里把帖子/文章作为物品来讲，行名和列名为用户和物品，每一项内容为用户对物品的评分，评分可以是是否点赞、是否评论的0和1，也可以是用户对物品的所有行为加权后的累加，例如点赞加1分，评论加2分，转发+5分，那么三连就是8分，什么都没做就是0分。在矩阵中要把用户和物品都改为序号，所以需要一个id和需要的映射表，矩阵长这样：

| 用户/物品 | 1    | 2    | 3    |
| --------- | ---- | ---- | ---- |
| 1         | 0    | 0    | 1    |
| 2         | 1    | 1    | 1    |
| 3         | 1    | 1    | 0    |

对这个表就可以进行计算了，用户1的矩阵就是[0, 0, 1]，用户2的就是[1, 1, 1]，对这两个数组做相似度的计算就可以得到用户1和用户2的相似程度，需要对所有用户进行两两计算，计算量是非常大的，所以需要构建一个稀疏矩阵来优化空间和加快运算，上面的矩阵在真实环境中会有百分之99以上的分值都是0，优化的核心只记录不为0的值，会保存为类似下面的矩阵，真实的结构远远比这个复杂，可以达到更小的空间占用，更优的计算效率

| 用户 | 物品 | 分值 |
| ---- | ---- | ---- |
| 1    | 3    | 1    |
| 2    | 1    | 1    |
| 2    | 2    | 1    |
| 2    | 3    | 1    |
| 3    | 1    | 1    |
| 3    | 2    | 1    |

再通过一些算法来计算相似度，内存、磁盘、计算时间都可以缩小成百上千倍，再根据每个用户的相似用户，找到相似用户喜欢的物品，根据他和用户的相似度，以及相似用户对这个物品的分值，加权得到推荐值。产生的结果就是相似用户和一个排好序的推荐列表，这就是基于用户的协同过滤。把上面的用户和物品矩阵转置一下，使用相同的算法，就是基于物品的协同过滤，可以得到一个物品的相似物品推荐和用户的推荐列表、喜欢它的人也喜欢

### 基于内容

另一类是基于内容的推荐算法，核心就是标签，简单原理是给每个物品提取标签，然后找到用户喜欢的物品，把物品的标签附加到用户身上，标签对于物品的权重越高，用户对物品的喜欢程度越高，这个标签在这个用户身上的权重就越高（用户的标签一定要来源于物品，否则就没有意义了），然后计算相似度，查找感兴趣的内容

优势：

1. 推荐结果可理解：标签
2. 推荐结果稳定性强：对于用户行为不丰富的类型，协同过滤很难找到同兴趣用户或关联产品，稀疏度太高。标签对用户兴趣捕捉稳定性远远高于单个产品
3. 便于人机协作：用户可勾选或关注推荐标签

劣势：

1. 不适合发现惊喜：如果一个产品不易于被标签穷举或标签还没出现，则很难被准确推荐
2. 在线应用复杂度高：需要基于每个用户来计算相似产品

两种方法：

方法一（one-hot编码 独热编码）：

1. 取出每个物品权重排名靠前的n个词作为标签，构建稀疏向量

2. 获取每个用户最近操作过的物品的标签，构建稀疏向量

3. 计算用户和物品、物品之间的相似度

4. 用户兴趣标签、人口统计学信息处理

   // 将每个标签（和性别年龄）分别作为向量的前几个维度，记录每个物品是否有这些属性；用户在选择标签时，将用户标签向量重新赋值，例如 0 1 0 0 xxx 改为 0 0 1 0 xxx

   用户的兴趣标签可扩展：通过话题聚类或找相似词，将相似的标签给用户（正确的做法是标签归一化，只保留同义标签中最正确的一个）

   标签过滤：

   1. 去掉词频很高的停止词
   2. 去掉同义词

   **可以给新用户打上整个系统最热门的标签（当用户未选择标签时，打上所有标签，数据库中不记录，只在推荐系统做判断）**

方法二（Embedding）：

1. 将所有物品的文字提取出来构建模型

2. 获取每个物品的embedding

   word2vec：分词，将每个词的词向量累加（求平均？），作为句子/文档的向量，在相关语义计算方面有优势，对于15字以内短句有效；简单的向量相加，丢掉了很多词和词之间的意思，无法更精确表达句子和句子之间的关系

   tf-idf：分词，以每个词的tf-idf为权重，对所有词向量加权平均

   doc2vec：适合长句子（效果较差）

3. 将用户最近操作过的物品的embedding取平均值，作为用户embedding

4. 相似度计算

5. 用户自己选择的兴趣标签和人口统计学信息如何处理

6. 聚类如何使用

标签有两种记录方法，对应的算法有有些不同，第一种就是文本的标签，标签什么样就保存为什么样，但是会有问题，对于同义词无法做区分，例如洗发水和洗发露，会占据两个标签，这就引出了另一种标签记录方式，就是词向量，词向量会根据上下文分析词的语义信息，保存为一个计算机才认识的多维矩阵，保存词的含义甚至上下文信息，同义词的词向量是很相似的，那么就可以认为是一个词，可以节省空间，让词库的质量更高，但是比较复杂，研究了一下，计算向量的效率太低，而且资料太少，不知道如何计算相似度，如何过滤同义词，先放弃，将来再研究。词向量想法是美好的，但是大多数还是使用中文的标签，因为词向量是不可解释的，只有机器能看懂，人看不懂，就无法作为文本展示给用户（这个展示的意思是像今日头条文章下面都会有文章标签列出来，还有可作为推荐一句，例如根据你喜欢的xx进行推荐）

分别对每个物品计算权重打标签，把所有的标签聚集起来按照权重和得到前1万-10万个标签，作为推荐标签库，构建物品-标签矩阵

|       | 标签1 | 标签2 | 标签3 |
| ----- | ----- | ----- | ----- |
| 物品1 | 0.1   | 0     | 0.5   |
| 物品2 | 0     | 0.23  | 0     |

再找到每个用户喜欢的物品，把物品的标签附加到用户身上，得到同样的用户-标签矩阵，那么物品1的矩阵为[0.1, 0, 0.5]，再计算每个用户对每个物品的相似度，排序后就得到用户的推荐结果。转换为稀疏矩阵，在一台配置很低的电脑上计算一个用户和10万物品的相似度，只需要0.01-0.1秒，再加上多进程就更快了

这种算法还可以部分解决冷启动问题，就是当一个新用户来时，需要他先填感兴趣的标签，再进行推荐，假如他填德甲，肯定不能只给他推荐德甲，还得推荐意甲、足球，甚至是篮球、运动相关，这就需要再次用到上面的文本库

把物品的所有文本构建一个文本库，这个文本库进行一些不同算法的训练，可得到词向量、话题聚类（机器学习的内容，不深讲，深讲我也不懂），通过词向量可找到一个词的n个相似词，例如通过德甲可以找到意甲；通过话题聚类可以给词库中所有的词分类，可找到一个词所属的类别，例如德甲会被分类到足球，足球会被分类到运动（现在话题聚类的文本库使用的是维基百科的语料库，效果比较好），把这些所有的标签添加到用户身上，会得到一个比较全面的推荐

上面的推荐算法已经可以作为第一版的推荐系统

### 其他

矩阵分解：把上面的大矩阵，分解成2个小矩阵，每个矩阵保存格式是向量，类似标签向量，除了实时计算，也可以优化达到更好的推荐效果，实质上也是属于协同过滤，只不过在分解的过程中用应用了机器学习的方法

深度学习：探索更深层次的特征关系，达到的效果更好，深度协同过滤

根据深度学习的特点，还可以加上另外一种推荐算法思路，根据所有用户的行为顺序来推测一个用户下一个会点消费什么物品，例如两个用户的顺序分别是1-2-3-4，1-2-4，第三个用户是1-2，那么他下一个想看的内容可能就是4，就把4放在推荐列表的前面，这个也实现了，但是还不准备用，第一版主要上上面两种常见算法

## 排序

上面就是召回的过程，通过这些算法分别得到这么多个推荐结果，我们如何知道哪些结果用户会感兴趣，就需要排序。推荐系统虽然核心是召回，但是对于成熟的系统来说，召回更重要，可以提高推荐的效果，而且可以不断的优化，难度也要比召回难的多，对效率和算法的要求也要高很多

排序主要是用模型融合，逻辑回归和梯度提升决策树组合、因子分解机、Wide & Deep 模型等算法，这一步把用户特征、物品特征加入进去，基于人口普查的有用户特征是在排序阶段使用的，例如用户年龄、用户地点、性别、物品创建地点等，再加入每次推荐的结果（用户感不感兴趣、有没有点击）训练模型，进行预测，属于浅层神经网络的机器学习，是根据用户特征预测用户对物品的喜欢程度。例如20岁北京女喜欢化妆品，20岁北京男喜欢玩游戏。但是构建特征数据比较困难，对空间和算法要求较高，也很难就暂时没有研究如何实现

多臂老虎机问题（MAB问题）用来探索新兴趣，主要是试探，它会推荐用户喜欢的和不知道喜不喜欢的物品，如果用户点击了物品，说明喜欢，下次多推，没点击，说明不喜欢，下次少推

## 其他算法

排行榜，一段时间更新一次的排行榜，部分解决冷启动问题，可给新用户已经所有用户推荐一些热门的内容（计划实现）。算法原理是降温，新加入的温度较高，热门物品温度较高，随着时间慢慢冷却，保证老的物品热度随时间降低，给新物品加入热门的机会，保留前1000个，保证前100个是可用的

重复检测：使用布隆过滤器对推荐结果进行去重，已推荐过的就不再推荐，效率高，可以对亿级数据进行快速查重，缺点就是有一定错误概率，概率是可以自定义的，每相差10倍概率就相差10倍的存储空间，所以设置为千分之一的错误概率是可以的，就是1000个推荐文章可能有1个是已经推荐过的（已实现）

## 架构

离线层：每天或者循环不停的构建矩阵，计算相似度，得到推荐列表，或构建机器学习模型，这些过程走完一个循环可能就要几个小时

近线层：接近实时但非实时，首先要有初始矩阵、机器学习模型，通过消息队列接收消息，每当有新的数据进就把这条数据加入到矩阵中，对相应的物品和用户进行实时的计算，或者加入到模型中进行训练，得到新的推荐列表保存到数据库。这一步做好就不太需要离线层了，但是已有算法都需要改，难度比较大

在线层：API，拿到上面两步得到的推荐结果，过滤掉已失效的物品，可加入些热门物品，获取到物品详情返回给前端展示
