2020-04-29

1. 排行榜每次只计算在榜内的物品行为和2天内的行为，保证随时都有数据，让两天内产生的新物品的行为不会被误删，让热度增长较慢但是一直有行为的物品也有上榜的机会，所以保留两天内的全部行为
2. 完成排行榜的统计报表功能。把当前排行榜中每个帖子的排行、ID、创建天数、热度、分值都输出到excel便于分析
3. 完成行为表的同步方法，取最大的id，把所有大于现有id的行为全部同步过来。排行数据更新逻辑也同步更新，分别记录每种数据的最大id，下次根据最大id来取（大量时间花费在时区处理，其实配置pymongo后，时区不用操心，都是中国）
4. 使用牛顿冷却算法排序，结果和按重力一样

2020-04-28

完成基于阅读量、点赞数、评论数排行榜算法

1. 初始化从最近1万条点赞、10万条阅读查找，之后每次循环都获取上次到现在之间的所有行为，重新计算排行榜，取前1000条；使用时间转化为ObjectId来查找，效率很高；将新的帖子同步到本地数据库，下次再查询创建时间更快
2. 行为去重，防止刷票（行为保存到csv，最后进行排序、过滤）

2020-04-27

1. 添加行为后实时计算该用户的相似用户
2. 使用稀疏矩阵计算基于用户推荐数据，优化速度，一个用户0.05-0.15秒
3. 规划排行榜的数据构建和算法

准备推荐系统讲解内容和讲解

2020-04-26

1. 总结推荐算法，总结1.0架构
2. 规划实时计算算法
3. 使用稀疏矩阵来重新计算基于用户的协同过滤，计算相似度，循环计算每个用户的相似物品，为实时计算做算法准备

豆瓣自动删除广播脚本

2020-04-24

1. 学习实时计算推荐，了解深度学习在推荐系统中的应用
2. 规划推荐系统整体算法以及运行逻辑，架构技术选型

2020-04-23

1. 使用布隆过滤器，规划好要保存的数据，支持保存到文件并读取
2. 测试在多进程中写入布隆过滤器，失败，因为Python进程之间对象是不可共享的
3. 学习推荐系统架构方法，日志收集方法、各种计算结果适合的数据库、API

2020-04-22

1.  归纳了几个分类，通过词向量查找分类相似的几个标签，作为用户兴趣的相似标签
2. 根据用户选择的标签为用户自动增加相似标签
3. 对维基百科语料处理和分词，3小时分别20、100、50个话题训练lda模型，50个话题效果最好，可以使用
4. 学习Wide & Deep 模型、探索新兴趣的算法、排行榜算法、采样算法、去重方法

2020-04-21

1. 学习多进程的批量操作，使用多进程计算内容推荐，1万用户260秒缩短为69秒
2. 多进程读取文章、取标签、分词、构建标签库、词库；数据库批量删除创建帖子对应标签
3. 重新训练话题聚类，不保留1个字的词，效果有所提升，但是还是一般，话题太聚集
4. 重新训练词向量，找相似词
5. 学习因子分解机

2020-04-20

1. 学习python多线程、多进程；使用多进程ProcessPoolExecutor对循环进行分片处理，每个核都达到充分的利用（出错是因为总数*10，导致分配任务时只有第一个任务的数组在范围内，其他的都执行完毕）
2. 研究文件多线程读取（不可以），多线程写入（需要锁，还不如直接写）
3. 优化基于标签的推荐方法，使用稀疏矩阵计算，省时省内存，一个用户的计算推荐耗时从2秒减少到0.2到0.01秒



本周完成在初步物品的协同过滤推荐算法；初步完成简单的基于标签/内容的推荐算法，可解决自定义标签、初步解决冷启动问题，原理是构建物品—标签矩阵，再根据用户行为构建对应的用户-标签矩阵，对两个矩阵计算两两相似度，可得到用户相近的物品排序，现有算法速度较慢，需要优化。以上实现在内存8G的机器都只能支持万x万级别的矩阵计算，远远达不到真实环境需求，最后研究了大数据的节省内存和优化速度方案，通过直接构建稀疏矩阵，再用稀疏矩阵直接计算相似度，可轻松支持百万x十万级别的矩阵计算。完成了词的聚类方法，可找到最热门的话题分布、将输入词进行归类，可对用户自定义标签达到很好的支持，还能解决冷启动问题

本周在研究基于内容的推荐算法时钻了牛角尖，想使用较难的向量方法实现，因为对向量和算法不熟，改用标签文本实现，不可能一步做到最好，可以将来熟悉后优化，标签文本还能很好的支持用户自定义标签。

本周遇到的最大问题还是在于网上资料太少，找到解决方案和方法纯属碰运气，大厂和学术文档太复杂不适用，仅有的大多数资料都是初学者，仅适合万级以下的数据

下周研究多核计算、分布式计算、矩阵分解，希望能支持更大的数据，有更高效的计算。优化基于内容的推荐，支持用户自定义标签和话题聚类

2020-04-17

主要研究大数据节省内存和优化速度方案
1. 研究基于内存的矩阵最大运算量，numpy不受影响，可以承受百万*百万的矩阵，但是涉及到矩阵计算，rdd、csr、相似度计算都只能支撑1万*1万的矩阵，甚至有些无法支撑10万*1万的计算
2. 研究直接生成稀疏矩阵以及直接通过稀疏矩阵计算相似度：直接通过lil_matrix切片矩阵分步创建稀疏矩阵，避免一次性塞入以及大尺寸数组导致内存极大占用，再转为csr，直接计算csr的相似度，占用内存极小，相似度找了两个算法，最后通过sklearn计算，秒级计算，并且测试百万*十万级数据也可支撑

2020-04-16

初步完成基于内容/标签的推荐

1. 构建物品-标签矩阵，使用pandas直接构建填充0的8w*1w的矩阵，太耗内存速度太慢，改为直接循环，构建为numpy矩阵
2. 构建用户-标签矩阵，从点赞表里获取用户点赞的帖子，将帖子标签赋给用户
3. 通过余弦相似度计算推荐内容，直接循环计算10万用户需要67天，使用numpy矩阵计算要5天，需要继续优化

学习逻辑回归和梯度提升决策树组合的模型融合

2020-04-15

1. 学习基于内容的推荐算法实践，分为两种，独热编码和向量，先使用独热编码简单实现，主要解决标签匹配和冷启动问题，实现简单，后续再优化为向量
2. 结巴引入停止词提升帖子分词质量
3. 完成lda聚类，将所有的词分为20大类，可对新的词进行归类
4. 学习基于标签的推荐，解决冷启动，和ALS矩阵分解

2020-04-14

1. 所有输出文件保留4位小数，节省空间
2. 10万帖子，分词，训练向量模型
3. 继续学习基于内容的推荐，推荐方法两种：1）基于向量的推荐。2）基于标签的索引查询算法

