2020-04-21

1. 学习多进程的批量操作，使用多进程计算内容推荐，1万用户260秒缩短为69秒
2. 多进程读取文章、取标签、分词、构建标签库、词库；数据库批量删除创建帖子对应标签
3. 重新训练话题聚类，不保留1个字的词，效果有所提升，但是还是一般，话题太聚集
4. 重新训练词向量，找相似词
5. 学习因子分解机

2020-04-20

1. 学习python多线程、多进程；使用多进程ProcessPoolExecutor对循环进行分片处理，每个核都达到充分的利用（出错是因为总数*10，导致分配任务时只有第一个任务的数组在范围内，其他的都执行完毕）
2. 研究文件多线程读取（不可以），多线程写入（需要锁，还不如直接写）
3. 优化基于标签的推荐方法，使用稀疏矩阵计算，省时省内存，一个用户的计算推荐耗时从2秒减少到0.2到0.01秒



本周完成在初步物品的协同过滤推荐算法；初步完成简单的基于标签/内容的推荐算法，可解决自定义标签、初步解决冷启动问题，原理是构建物品—标签矩阵，再根据用户行为构建对应的用户-标签矩阵，对两个矩阵计算两两相似度，可得到用户相近的物品排序，现有算法速度较慢，需要优化。以上实现在内存8G的机器都只能支持万x万级别的矩阵计算，远远达不到真实环境需求，最后研究了大数据的节省内存和优化速度方案，通过直接构建稀疏矩阵，再用稀疏矩阵直接计算相似度，可轻松支持百万x十万级别的矩阵计算。完成了词的聚类方法，可找到最热门的话题分布、将输入词进行归类，可对用户自定义标签达到很好的支持，还能解决冷启动问题

本周在研究基于内容的推荐算法时钻了牛角尖，想使用较难的向量方法实现，因为对向量和算法不熟，改用标签文本实现，不可能一步做到最好，可以将来熟悉后优化，标签文本还能很好的支持用户自定义标签。

本周遇到的最大问题还是在于网上资料太少，找到解决方案和方法纯属碰运气，大厂和学术文档太复杂不适用，仅有的大多数资料都是初学者，仅适合万级以下的数据

下周研究多核计算、分布式计算、矩阵分解，希望能支持更大的数据，有更高效的计算。优化基于内容的推荐，支持用户自定义标签和话题聚类

2020-04-17

主要研究大数据节省内存和优化速度方案
1. 研究基于内存的矩阵最大运算量，numpy不受影响，可以承受百万*百万的矩阵，但是涉及到矩阵计算，rdd、csr、相似度计算都只能支撑1万*1万的矩阵，甚至有些无法支撑10万*1万的计算
2. 研究直接生成稀疏矩阵以及直接通过稀疏矩阵计算相似度：直接通过lil_matrix切片矩阵分步创建稀疏矩阵，避免一次性塞入以及大尺寸数组导致内存极大占用，再转为csr，直接计算csr的相似度，占用内存极小，相似度找了两个算法，最后通过sklearn计算，秒级计算，并且测试百万*十万级数据也可支撑

2020-04-16

初步完成基于内容/标签的推荐

1. 构建物品-标签矩阵，使用pandas直接构建填充0的8w*1w的矩阵，太耗内存速度太慢，改为直接循环，构建为numpy矩阵
2. 构建用户-标签矩阵，从点赞表里获取用户点赞的帖子，将帖子标签赋给用户
3. 通过余弦相似度计算推荐内容，直接循环计算10万用户需要67天，使用numpy矩阵计算要5天，需要继续优化

学习逻辑回归和梯度提升决策树组合的模型融合

2020-04-15

1. 学习基于内容的推荐算法实践，分为两种，独热编码和向量，先使用独热编码简单实现，主要解决标签匹配和冷启动问题，实现简单，后续再优化为向量
2. 结巴引入停止词提升帖子分词质量
3. 完成lda聚类，将所有的词分为20大类，可对新的词进行归类
4. 学习基于标签的推荐，解决冷启动，和ALS矩阵分解

2020-04-14

1. 所有输出文件保留4位小数，节省空间
2. 10万帖子，分词，训练向量模型
3. 继续学习基于内容的推荐，推荐方法两种：1）基于向量的推荐。2）基于标签的索引查询算法

